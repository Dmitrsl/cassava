{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.prepare_data import get_loaders\n",
    "from utils.models import CassavaNet, get_params\n",
    "from utils.settings import seed_everything\n",
    "from utils.dataset import CassavaDataset\n",
    "from utils.transforms import get_train_transforms, get_valid_transforms, get_inference_transforms\n",
    "from utils.predict import inference_one_epoch, tta_predict\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm \n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import catalyst\n",
    "import multiprocessing\n",
    "import collections\n",
    "from scipy.stats import gmean, hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEED: 2021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'tf_efficientnet_b2_ns'\n",
    "fold = 1\n",
    "ROOT = Path(os.getcwd())/ 'cassava-leaf-disease-classification'\n",
    "OUTPUT_ROOT = ROOT / 'out'\n",
    "SEED = 2021\n",
    "seed_everything(SEED)\n",
    "NUM_CORES = multiprocessing.cpu_count() - 2\n",
    "BS = 16\n",
    "img_size=528\n",
    "\n",
    "train = pd.read_csv(ROOT / 'train_cv7_add.csv')\n",
    "valid_fold = train[train[f\"fold_{fold}\"] == 'test']\n",
    "valid_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_valid_transforms(img_size = img_size))\n",
    "infer_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_inference_transforms(img_size = img_size))\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "infer_loader = torch.utils.data.DataLoader(infer_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "\n",
    "\n",
    "\n",
    "device = catalyst.utils.get_device()\n",
    "model = CassavaNet(5, model_name).to(device)\n",
    "logdir = f\"{OUTPUT_ROOT}/.logs_{model_name}_{fold}_stage_2_1/checkpoints/\"\n",
    "model_dict = torch.load(f'{logdir}/best.pth', map_location=device)['model_state_dict']\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from albumentations import (\n",
    "#     HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, \n",
    "#     Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "#     IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, \n",
    "#     IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout,\n",
    "#     ShiftScaleRotate, CenterCrop, Resize, SmallestMaxSize,\n",
    "#     RandomSunFlare, RandomShadow, RandomResizedCrop, CoarseDropout, RandomGridShuffle\n",
    "# )\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# mean=[0.485, 0.456, 0.406], \n",
    "# std=[0.229, 0.224, 0.225]\n",
    "# n_tta = 4\n",
    "# # def get_inference_transforms(img_size = 528):\n",
    "# #     return Compose([\n",
    "# #             SmallestMaxSize(img_size,interpolation=2, p=1.),\n",
    "# #             CenterCrop(img_size, img_size, p=1.),\n",
    "        \n",
    "# #             OneOf(\n",
    "# #                 [\n",
    "# #                 #Transpose(p=1),\n",
    "# #                 HorizontalFlip(p=0.25),\n",
    "# #                 #VerticalFlip(p=0.5),\n",
    "# #                 ShiftScaleRotate(p=0.25),\n",
    "# #                 HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.25),\n",
    "# #                 #RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=1),\n",
    "# #                 CoarseDropout(p=0.25),\n",
    "# #                 #Cutout(p=1),\n",
    "# #                 #RandomGridShuffle(grid=(3, 3), p=1)\n",
    "# #                 ], p=1),\n",
    "        \n",
    "# #             Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "# #             ToTensorV2(p=1.0),\n",
    "# #         ], p=1.)\n",
    "\n",
    "# train = pd.read_csv(ROOT / 'train_cv7_add.csv')\n",
    "# valid_fold = train[train[f\"fold_{fold}\"] == 'test']\n",
    "# valid_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_valid_transforms(img_size = img_size))\n",
    "# infer_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_inference_transforms(img_size = img_size))\n",
    "# valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "# infer_loader = torch.utils.data.DataLoader(infer_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "\n",
    "\n",
    "\n",
    "# device = catalyst.utils.get_device()\n",
    "# model = CassavaNet(5, model_name).to(device)\n",
    "# logdir = f\"{OUTPUT_ROOT}/.logs_{model_name}_{fold}_stage_2_1/checkpoints/\"\n",
    "# model_dict = torch.load(f'{logdir}/best.pth', map_location=device)['model_state_dict']\n",
    "# model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inference_one_epoch(model, data_loader, device):\n",
    "#     model.eval()\n",
    "\n",
    "#     image_preds_all = []\n",
    "#     labels = []\n",
    "    \n",
    "#     pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n",
    "#     for step, (imgs) in pbar:\n",
    "\n",
    "#         img = imgs[0].to(device).float()\n",
    "\n",
    "#         labels_batch = imgs[1]\n",
    "\n",
    "#         image_preds = model(img)   #output = model(input)\n",
    "#         image_preds_all += [torch.softmax(image_preds, 1).detach().cpu().numpy()]\n",
    "#         labels += [labels_batch]\n",
    "        \n",
    "#     image_preds_all = np.concatenate(image_preds_all, axis=0)\n",
    "#     labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "#     return image_preds_all, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tta_predict(model, infer_loader, valid_loader, device, func='gmean'):\n",
    "    \n",
    "#     tta_preds = []\n",
    "#     model.eval()\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         no_tta_preds, no_tta_labels = inference_one_epoch(model, valid_loader, device)\n",
    "\n",
    "#         for _ in range(n_tta):\n",
    "#             tta, _ = inference_one_epoch(model, infer_loader, device)\n",
    "#             tta_preds += [tta]\n",
    "#             tta_preds += [no_tta_preds]\n",
    "\n",
    "#     if func == 'gmean':\n",
    "#         tta_preds = gmean(tta_preds, axis=0) \n",
    "#     else:\n",
    "#         tta_preds = np.mean(tta_preds, axis=0) \n",
    "#     return tta_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db73b9d78cdf419c9947578f7be416eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9934dd23ebd4071b8d424b790703aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f67332a5b84f2e9122ca671fe13c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a0a0bd82ea40828f69a00c147d4e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad6eb9e70da40089af85883339074ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tta_preds = tta_predict(4, model, infer_loader, valid_loader, device, func='gmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f630a86fb6cf47d39eb733667056b506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=236.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    no_tta_preds, no_tta_labels = inference_one_epoch(model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8987509965453095"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(no_tta_labels, np.argmax(tta_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_preds_ = gmean([tta_preds, no_tta_preds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894764815306936"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(no_tta_labels, np.argmax(no_tta_preds, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8982195057135265"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(no_tta_labels, np.argmax(tta_preds_, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gmean\n",
    "\n",
    "11 0.8963592878022855\n",
    "\n",
    "9 0.8958277969705023\n",
    "\n",
    "np.mean\n",
    "\n",
    "0.8968907786340685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3763, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fold = 1\n",
    "train = pd.read_csv(ROOT / 'train_cv7_add.csv')\n",
    "valid_fold = train[train[f\"fold_{fold}\"] == 'test']\n",
    "cat_fold = train[train[f\"fold_{fold}\"] == 'train']\n",
    "\n",
    "cat_ds = CassavaDataset(cat_fold, ROOT / 'train/', transforms=get_inference_transforms(img_size = img_size))\n",
    "valid_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_valid_transforms(img_size = img_size))\n",
    "infer_ds = CassavaDataset(valid_fold, ROOT / 'train/', transforms=get_inference_transforms(img_size = img_size))\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "infer_loader = torch.utils.data.DataLoader(infer_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n",
    "cat_loader = torch.utils.data.DataLoader(cat_ds, batch_size=BS, num_workers=NUM_CORES, shuffle=False, pin_memory=False,) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_preds = []\n",
    "# tta_preds = []\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for _ in tqdm(range(n_tta)):\n",
    "#         tta, _ = inference_one_epoch(model, cat_loader, device)\n",
    "#         tta_preds += [tta]\n",
    "\n",
    "# tta_preds = gmean(tta_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d37f8c5e4624c3c8ab7b0b50c2909fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=13.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91c3c61b7e541889af1c6ce1041023f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1411.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-66dc2d18adff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtta_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cassava/utils/predict.py\u001b[0m in \u001b[0;36minference_one_epoch\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimage_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#output = model(input)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mimage_preds_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = catalyst.utils.get_device()\n",
    "model = CassavaNet(5, model_name).to(device)\n",
    "logdir = f\"{OUTPUT_ROOT}/.logs_{model_name}_{fold}_stage_2_1/checkpoints/\"\n",
    "model_dict = torch.load(f'{logdir}/best.pth', map_location=device)['model_state_dict']\n",
    "model.load_state_dict(model_dict)\n",
    "\n",
    "val_preds = []\n",
    "tta_preds = []\n",
    "n_tta = 13\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for _ in tqdm(range(n_tta)):\n",
    "        tta, _ = inference_one_epoch(model, cat_loader, device)\n",
    "        tta_preds += [tta]\n",
    "\n",
    "tta_preds = gmean(tta_preds, axis=0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    no_tta_preds, tta_labels = inference_one_epoch(model, cat_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(tta_labels, np.argmax(tta_preds, 1))) #\n",
    "print(accuracy_score(tta_labels, np.argmax(no_tta_preds, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    no_tta_preds_val, no_tta_labels_val = inference_one_epoch(model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tta_preds\n",
    "\n",
    "train_labels = tta_labels\n",
    "\n",
    "test_data = Pool(no_tta_preds_val, no_tta_labels_val)\n",
    "\n",
    "cat_model = CatBoostClassifier(iterations=2000,\n",
    "                           depth=2,\n",
    "                           learning_rate=0.01,\n",
    "                           loss_function='MultiClassOneVsAll', #''MultiClass',\n",
    "                           early_stopping_rounds=30,\n",
    "                           #loss_function='CrossEntropy',\n",
    "                           #verbose=200\n",
    "                              )\n",
    "# train the model\n",
    "cat_model.fit(train_data, train_labels,\n",
    "    eval_set=(no_tta_preds_val, no_tta_labels_val),\n",
    "    verbose=False,\n",
    "    plot=True\n",
    "             )\n",
    "# make the prediction using the resulting model\n",
    "preds_class = cat_model.predict(test_data)\n",
    "preds_proba = cat_model.predict_proba(test_data)\n",
    "\n",
    "print(accuracy_score(no_tta_labels_val, preds_class))\n",
    "print(accuracy_score(no_tta_labels_val, np.argmax(no_tta_preds_val, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(no_tta_labels_val, preds_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
