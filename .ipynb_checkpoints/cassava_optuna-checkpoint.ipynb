{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNSV6YYGohfF"
   },
   "source": [
    "Forked from [Kun Hao Yeh notebook](https://www.kaggle.com/khyeh0719/pytorch-efficientnet-baseline-inference-tta) and changed some small parameters.\n",
    "\n",
    "Please upvote the original notebook as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39
    },
    "id": "CzIU9ce-kwfZ",
    "outputId": "94c7c2cc-7153-4ac6-c8d8-5fb5227b833c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2080 Ti'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A7b3so0UnqGt",
    "outputId": "04e7ee1f-ce56-429c-dc98-4e3bf6376c34",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: целевой путь «apex» уже существует и не является пустым каталогом.\n",
      "/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py:235: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
      "  cmdoptions.check_install_build_global(options)\n",
      "Using pip 20.2.4 from /home/dgpu/miniconda3/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Non-user install because site-packages writeable\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-8ebirkkh\n",
      "Created temporary directory: /tmp/pip-req-tracker-i3lq_el_\n",
      "Initialized build tracking at /tmp/pip-req-tracker-i3lq_el_\n",
      "Created build tracker: /tmp/pip-req-tracker-i3lq_el_\n",
      "Entered build tracker: /tmp/pip-req-tracker-i3lq_el_\n",
      "Created temporary directory: /tmp/pip-install-b_bmmtzo\n",
      "Processing ./apex\n",
      "  Created temporary directory: /tmp/pip-req-build-4ny0rwt6\n",
      "  Added file:///media/dgpu/flash500/cassava/apex to build tracker '/tmp/pip-req-tracker-i3lq_el_'\n",
      "    Running setup.py (path:/tmp/pip-req-build-4ny0rwt6/setup.py) egg_info for package from file:///media/dgpu/flash500/cassava/apex\n",
      "    Created temporary directory: /tmp/pip-pip-egg-info-5vhlwvk5\n",
      "    Running command python setup.py egg_info\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.4.0\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-4ny0rwt6/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "    running egg_info\n",
      "    creating /tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info\n",
      "    writing /tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to /tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to /tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/top_level.txt\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file '/tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file '/tmp/pip-pip-egg-info-5vhlwvk5/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-4ny0rwt6 has version 0.1, which satisfies requirement apex==0.1 from file:///media/dgpu/flash500/cassava/apex\n",
      "  Removed apex==0.1 from file:///media/dgpu/flash500/cassava/apex from build tracker '/tmp/pip-req-tracker-i3lq_el_'\n",
      "Skipping wheel build for apex, due to binaries being disabled for it.\n",
      "Installing collected packages: apex\n",
      "  Attempting uninstall: apex\n",
      "    Found existing installation: apex 0.1\n",
      "    Uninstalling apex-0.1:\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/~pex-0.1.dist-info\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex-0.1.dist-info/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~NN\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/RNN/\n",
      "      Created temporary directory: /tmp/pip-uninstall-n1dffb24\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__init__.py\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~_pycache__\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__pycache__/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~mp\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/amp/\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__init__.py\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~_pycache__\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__pycache__/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~roupbn\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/groupbn/\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__init__.py\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/__init__.cpython-37.pyc\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fp16_optimizer.cpython-37.pyc\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fused_adam.cpython-37.pyc\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fp16_optimizer.py\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fused_adam.py\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~entropy\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/xentropy/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~p16_utils\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/fp16_utils/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ulti_tensor_apply\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/multi_tensor_apply/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ormalization\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/normalization/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ptimizers\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/optimizers/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~arallel\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/parallel/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~yprof\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/pyprof/\n",
      "      Created temporary directory: /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~eparameterization\n",
      "      Removing file or directory /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/reparameterization/\n",
      "      Successfully uninstalled apex-0.1\n",
      "  Created temporary directory: /tmp/pip-record-w2krjkuf\n",
      "    Running setup.py install for apex ... \u001b[?25l    Running command /home/dgpu/miniconda3/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-w2krjkuf/install-record.txt --single-version-externally-managed --compile --install-headers /home/dgpu/miniconda3/include/python3.7m/apex\n",
      "\n",
      "\n",
      "    torch.__version__  = 1.4.0\n",
      "\n",
      "\n",
      "    /tmp/pip-req-build-4ny0rwt6/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
      "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-req-build-4ny0rwt6/setup.py\", line 169, in <module>\n",
      "        raise RuntimeError(\"--cuda_ext was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\")\n",
      "    RuntimeError: --cuda_ext was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n",
      "\u001b[?25herror\n",
      "  Rolling back uninstall of apex\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex-0.1.dist-info/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/~pex-0.1.dist-info\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/RNN/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~NN\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__init__.py\n",
      "   from /tmp/pip-uninstall-n1dffb24/__init__.py\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__pycache__/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~_pycache__\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/amp/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~mp\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__init__.py\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/__init__.py\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__pycache__/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~_pycache__\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/groupbn/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~roupbn\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__init__.py\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__init__.py\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/__init__.cpython-37.pyc\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/__init__.cpython-37.pyc\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fp16_optimizer.cpython-37.pyc\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/fp16_optimizer.cpython-37.pyc\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fused_adam.cpython-37.pyc\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/fused_adam.cpython-37.pyc\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fp16_optimizer.py\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/fp16_optimizer.py\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fused_adam.py\n",
      "   from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/fused_adam.py\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/xentropy/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~entropy\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/fp16_utils/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~p16_utils\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/multi_tensor_apply/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ulti_tensor_apply\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/normalization/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ormalization\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/optimizers/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ptimizers\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/parallel/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~arallel\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/pyprof/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~yprof\n",
      "  Moving to /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/reparameterization/\n",
      "   from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~eparameterization\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex-0.1.dist-info/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/~pex-0.1.dist-info\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/RNN/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~NN\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__init__.py from /tmp/pip-uninstall-n1dffb24/__init__.py\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/__pycache__/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~_pycache__\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/amp/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~mp\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__init__.py from /tmp/pip-uninstall-n1dffb24/contrib/__init__.py\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/__pycache__/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~_pycache__\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/groupbn/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~roupbn\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__init__.py from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__init__.py\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/__init__.cpython-37.pyc from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/__init__.cpython-37.pyc\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fp16_optimizer.cpython-37.pyc from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/fp16_optimizer.cpython-37.pyc\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/__pycache__/fused_adam.cpython-37.pyc from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/__pycache__/fused_adam.cpython-37.pyc\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fp16_optimizer.py from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/fp16_optimizer.py\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/optimizers/fused_adam.py from /tmp/pip-uninstall-n1dffb24/contrib/optimizers/fused_adam.py\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/xentropy/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/contrib/~entropy\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/fp16_utils/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~p16_utils\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/multi_tensor_apply/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ulti_tensor_apply\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/normalization/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ormalization\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/optimizers/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~ptimizers\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/parallel/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~arallel\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/pyprof/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~yprof\n",
      "  Replacing /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/reparameterization/ from /home/dgpu/miniconda3/lib/python3.7/site-packages/apex/~eparameterization\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /home/dgpu/miniconda3/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-w2krjkuf/install-record.txt --single-version-externally-managed --compile --install-headers /home/dgpu/miniconda3/include/python3.7m/apex Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception information:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 852, in install\n",
      "    req_description=str(self.req),\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/operations/install/legacy.py\", line 86, in install\n",
      "    raise LegacyInstallFailure\n",
      "pip._internal.operations.install.legacy.LegacyInstallFailure\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/cli/base_command.py\", line 228, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/cli/req_command.py\", line 182, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/commands/install.py\", line 406, in run\n",
      "    pycompile=options.compile,\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/req/__init__.py\", line 90, in install_given_reqs\n",
      "    pycompile=pycompile,\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/req/req_install.py\", line 856, in install\n",
      "    six.reraise(*exc.parent)\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_vendor/six.py\", line 703, in reraise\n",
      "    raise value\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/operations/install/legacy.py\", line 76, in install\n",
      "    cwd=unpacked_source_directory,\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/utils/subprocess.py\", line 277, in runner\n",
      "    spinner=spinner,\n",
      "  File \"/home/dgpu/miniconda3/lib/python3.7/site-packages/pip/_internal/utils/subprocess.py\", line 242, in call_subprocess\n",
      "    raise InstallationError(exc_msg)\n",
      "pip._internal.exceptions.InstallationError: Command errored out with exit status 1: /home/dgpu/miniconda3/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-4ny0rwt6/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-w2krjkuf/install-record.txt --single-version-externally-managed --compile --install-headers /home/dgpu/miniconda3/include/python3.7m/apex Check the logs for full command output.\n",
      "1 location(s) to search for versions of pip:\n",
      "* https://pypi.org/simple/pip/\n",
      "Fetching project page and analyzing links: https://pypi.org/simple/pip/\n",
      "Getting page https://pypi.org/simple/pip/\n",
      "Found index url https://pypi.org/simple\n",
      "Starting new HTTPS connection (1): pypi.org:443\n",
      "Could not fetch URL https://pypi.org/simple/pip/: connection error: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f2ba92cb950>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))) - skipping\n",
      "Given no hashes to check 0 links for project 'pip': discarding no candidates\n",
      "Removed build tracker: '/tmp/pip-req-tracker-i3lq_el_'\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VW8TBo9GpHSB",
    "outputId": "df74b4f1-f8a4-4ab0-8f3e-d9d2f044df6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: timm in /home/dgpu/miniconda3/lib/python3.7/site-packages (0.1.18)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from timm) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: torchvision in /home/dgpu/miniconda3/lib/python3.7/site-packages (from timm) (0.5.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /home/dgpu/miniconda3/lib/python3.7/site-packages (from torchvision->timm) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/dgpu/miniconda3/lib/python3.7/site-packages (from torchvision->timm) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from torchvision->timm) (7.2.0)\n",
      "Requirement already up-to-date: catalyst in /home/dgpu/miniconda3/lib/python3.7/site-packages (20.7)\n",
      "Requirement already satisfied, skipping upgrade: deprecation in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: PyYAML in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (5.3)\n",
      "Requirement already satisfied, skipping upgrade: tensorboardX in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (2.0)\n",
      "Requirement already satisfied, skipping upgrade: plotly>=4.1.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (4.9.0)\n",
      "Requirement already satisfied, skipping upgrade: GitPython>=3.1.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (3.1.7)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (20.4)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard>=1.14.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (0.22.1)\n",
      "Requirement already satisfied, skipping upgrade: torch>=1.1.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (1.4.0)\n",
      "Requirement already satisfied, skipping upgrade: ipython in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (7.16.1)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.22 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (3.3.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm>=4.33.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (4.43.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.16.4 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from catalyst) (1.19.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboardX->catalyst) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboardX->catalyst) (3.12.2)\n",
      "Requirement already satisfied, skipping upgrade: retrying>=1.3.3 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from plotly>=4.1.0->catalyst) (1.3.3)\n",
      "Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from GitPython>=3.1.1->catalyst) (4.0.5)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from packaging->catalyst) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (1.30.0)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (45.2.0.post20200209)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (0.34.2)\n",
      "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (1.22.1)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from tensorboard>=1.14.0->catalyst) (0.9.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from scikit-learn>=0.20->catalyst) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from scikit-learn>=0.20->catalyst) (0.16.0)\n",
      "Requirement already satisfied, skipping upgrade: jedi>=0.10 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (0.17.2)\n",
      "Requirement already satisfied, skipping upgrade: decorator in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (4.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (4.8.0)\n",
      "Requirement already satisfied, skipping upgrade: backcall in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (4.3.3)\n",
      "Requirement already satisfied, skipping upgrade: pickleshare in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (0.7.5)\n",
      "Requirement already satisfied, skipping upgrade: pygments in /home/dgpu/miniconda3/lib/python3.7/site-packages (from ipython->catalyst) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from pandas>=0.22->catalyst) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from pandas>=0.22->catalyst) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from matplotlib->catalyst) (7.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from matplotlib->catalyst) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from matplotlib->catalyst) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: smmap<4,>=3.0.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.1->catalyst) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=1.14.0->catalyst) (1.25.7)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /home/dgpu/miniconda3/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.5\" in /home/dgpu/miniconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.2.8)\n",
      "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (4.1.1)\n",
      "Requirement already satisfied, skipping upgrade: parso<0.8.0,>=0.7.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython->catalyst) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython->catalyst) (0.6.0)\n",
      "Requirement already satisfied, skipping upgrade: wcwidth in /home/dgpu/miniconda3/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->catalyst) (0.1.8)\n",
      "Requirement already satisfied, skipping upgrade: ipython-genutils in /home/dgpu/miniconda3/lib/python3.7/site-packages (from traitlets>=4.2->ipython->catalyst) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14.0->catalyst) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=1.14.0->catalyst) (3.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /home/dgpu/miniconda3/lib/python3.7/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2,>=1.6.3->tensorboard>=1.14.0->catalyst) (0.4.8)\n",
      "Collecting git+https://github.com/albumentations-team/albumentations\n",
      "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-wbhaqwpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7556869bd0>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/timm/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7555950e10>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/timm/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7555950390>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/timm/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7555950210>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/timm/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f7555950fd0>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/timm/\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8da43c1850>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/catalyst/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8da34a8350>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/catalyst/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8da34a8390>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/catalyst/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8da34a8dd0>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/catalyst/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7f8da34a8910>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/catalyst/\n",
      "ERROR: Command errored out with exit status 128: git clone -q https://github.com/albumentations-team/albumentations /tmp/pip-req-build-wbhaqwpg Check the logs for full command output.\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc75312ffd0>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/vision-transformer-pytorch/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc75339cd10>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/vision-transformer-pytorch/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc754070250>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/vision-transformer-pytorch/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc7540703d0>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/vision-transformer-pytorch/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7fc754070d50>: Failed to establish a new connection: [Errno 113] Нет маршрута до узла'))': /simple/vision-transformer-pytorch/\n",
      "ERROR: Could not find a version that satisfies the requirement vision_transformer_pytorch (from versions: none)\n",
      "ERROR: No matching distribution found for vision_transformer_pytorch\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'pip install -U timm\\npip install -U catalyst\\npip install -U git+https://github.com/albumentations-team/albumentations\\npip install vision_transformer_pytorch\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-48b978eb5d61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pip install -U timm\\npip install -U catalyst\\npip install -U git+https://github.com/albumentations-team/albumentations\\npip install vision_transformer_pytorch\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2369\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2371\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2372\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'pip install -U timm\\npip install -U catalyst\\npip install -U git+https://github.com/albumentations-team/albumentations\\npip install vision_transformer_pytorch\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install -U timm\n",
    "pip install -U catalyst\n",
    "pip install -U git+https://github.com/albumentations-team/albumentations\n",
    "pip install vision_transformer_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYQuRdf3ohfS"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from sklearn.model_selection import GroupKFold, StratifiedKFold\n",
    "import cv2\n",
    "from skimage import io\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "from  torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import sklearn\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn import metrics\n",
    "import warnings\n",
    "import cv2\n",
    "#import pydicom\n",
    "import timm #from efficientnet_pytorch import EfficientNet\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQKOO0jy-aAC"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UARk5for4O7"
   },
   "outputs": [],
   "source": [
    "from catalyst.utils import set_global_seed, prepare_cudnn, get_device\n",
    "import multiprocessing\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Callable, List, Tuple \n",
    "from vision_transformer_pytorch import VisionTransformer\n",
    "\n",
    "\n",
    "from catalyst.dl import utils\n",
    "##from catalyst.data.reader import ImageReader, ScalarReader, ReaderCompose\n",
    "from catalyst.utils import imread\n",
    "#from catalyst.utils.dataset import create_dataset, create_dataframe, prepare_dataset_labeling\n",
    "#from catalyst.utils.pandas import map_dataframe\n",
    "#from catalyst.data.dataset import PathsDataset\n",
    "#from catalyst.utils.dataset import split_dataframe, stratified_fold_split, default_fold_split, create_dataset\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.contrib.nn.criterion.focal import FocalLossMultiClass\n",
    "from catalyst.dl.callbacks import AccuracyCallback, AUCCallback, F1ScoreCallback\n",
    "from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n",
    "#from catalyst.data.augmentor import Augmentor\n",
    "from catalyst.contrib.nn.optimizers import RAdam, Lookahead\n",
    "\n",
    "from catalyst.dl.callbacks import DiceCallback, IouCallback, \\\n",
    "  CriterionCallback, OptimizerCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DFkUiGEWohfT"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'fold_num': 10,\n",
    "    'seed': 719,\n",
    "    'model_arch': 'tf_efficientnet_b4_ns',\n",
    "    'img_size': 384,\n",
    "    'epochs': 32,\n",
    "    'train_bs': 16,\n",
    "    'valid_bs': 16,\n",
    "    'lr': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'accum_iter': 1, # suppoprt to do batch accumulation for backprop with effectively larger batch size\n",
    "    'verbose_step': 1,\n",
    "    'device': 'cuda:0',\n",
    "    'tta': 3,\n",
    "    'used_epochs': [6,7,8,9],\n",
    "    'weights': [1,1,1,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "572LmkqmpyiP",
    "outputId": "fad86036-7214-40de-cdaa-becac667557c"
   },
   "outputs": [],
   "source": [
    "root = Path(os.getcwd())/ 'cassava-leaf-disease-classification'\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "BGUQdVEJohfU",
    "outputId": "9e88fc20-7414-4f69-8487-669f220cb3d1"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(root / 'merged.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "KBrQn9lmohfV",
    "outputId": "974d58ca-d20f-41eb-e789-4a8625770447"
   },
   "outputs": [],
   "source": [
    "train.label.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGmyFAfPohfV"
   },
   "source": [
    "> We could do stratified validation split in each fold to make each fold's train and validation set looks like the whole train set in target distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x1oU7oMohfW"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_0oTimttFVN",
    "outputId": "e1908a53-2f33-4142-8ea2-886e5675751d"
   },
   "outputs": [],
   "source": [
    "NUM_CORES = multiprocessing.cpu_count() - 1\n",
    "SEED = 2021\n",
    "NUM_CORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "pLu13lq5ohfX",
    "outputId": "163ddfe3-f84f-4c98-d2e6-66ecc1351ffd"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "def seed_everything(seed):\n",
    "    set_global_seed(SEED)\n",
    "    prepare_cudnn()\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    print(f'SEED: {SEED}')\n",
    " \n",
    "def show_examples(images: List[Tuple[str, np.ndarray]]):\n",
    "    examples = len(images)\n",
    "    width = int(examples ** .5)\n",
    "    height = examples // width\n",
    "    _indexes = [(i, j) for i in range(height) for j in range(width)]\n",
    "    \n",
    "    f, ax = plt.subplots(height, width, figsize=(16, 16))\n",
    "    for (i, j), (title, img) in zip(_indexes, images):\n",
    "        ax[i, j].imshow(img)\n",
    "        ax[i, j].set_title(title)\n",
    "    f.tight_layout()\n",
    "\n",
    "def read_random_images(paths: List[Path], size: int=4) -> List[Tuple[str, np.ndarray]]:\n",
    "    data = np.random.choice(paths, size)\n",
    "    result = []\n",
    "    for d in data:\n",
    "        name = d.name\n",
    "        #title = '_'.join([str(i) for i in train[train.image_id == name].values[0]])\n",
    "        title = train[train.image_id == name].values[0][3]\n",
    "        _image = get_img(d)\n",
    "        result.append((title, _image))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_img(path):\n",
    "    im_bgr = cv2.imread(str(path))\n",
    "    im_rgb = im_bgr[:, :, ::-1]\n",
    "    #print(im_rgb)\n",
    "    return im_rgb\n",
    "\n",
    "img = get_img(root / 'train/1000201771.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBKhoGo0txY5",
    "outputId": "d7e2c3f4-aaa1-4103-e6f1-0fe9bad0939c"
   },
   "outputs": [],
   "source": [
    "root / 'train/1000201771.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "jfJPosvkHuFn",
    "outputId": "616794e9-cd8a-4ee4-c1be-695ad45f1850"
   },
   "outputs": [],
   "source": [
    "class_map = pd.read_json(root / 'label_num_to_disease_map.json', orient='index')\n",
    "class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 39
    },
    "id": "LdX9ECuMMMiM",
    "outputId": "02909965-35fa-4586-d58a-7aad6cb3e32d"
   },
   "outputs": [],
   "source": [
    "'_'.join([str(i) for i in train[train.image_id == '1000015157.jpg'].values[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "BIlttWhFKwZo",
    "outputId": "25c3ba32-82d9-45ec-daf8-1517a0a519d3"
   },
   "outputs": [],
   "source": [
    "train = train.merge(class_map, left_on='label', right_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zgScvpzmGQ0-",
    "outputId": "f56c816f-576f-46f0-935b-1ea7e58a5ebe"
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = root / 'train'\n",
    "train_imades = list(Path(TRAIN_DIR).glob(\"**/*.jpg\"))\n",
    "images = read_random_images(train_imades, 16)\n",
    "show_examples(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqytICeuohfZ"
   },
   "source": [
    "# Define Train\\Validation Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upqrNFcfnQes"
   },
   "outputs": [],
   "source": [
    "mean = [0.4589, 0.5314, 0.3236]\n",
    "std = [0.2272, 0.2297, 0.2200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIVYnsfyohfa"
   },
   "outputs": [],
   "source": [
    "# from albumentations import (\n",
    "#     HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90,\n",
    "#     Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "#     IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, RandomResizedCrop,\n",
    "#     IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, CoarseDropout, ShiftScaleRotate, CenterCrop, Resize\n",
    "# )\n",
    "\n",
    "# from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from albumentations import (\n",
    "    HorizontalFlip, VerticalFlip, IAAPerspective, ShiftScaleRotate, CLAHE, RandomRotate90, \n",
    "    Transpose, ShiftScaleRotate, Blur, OpticalDistortion, GridDistortion, HueSaturationValue,\n",
    "    IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, MedianBlur, IAAPiecewiseAffine, \n",
    "    IAASharpen, IAAEmboss, RandomBrightnessContrast, Flip, OneOf, Compose, Normalize, Cutout, ShiftScaleRotate, CenterCrop, Resize,SmallestMaxSize\n",
    "    # RandomSunFlare, RandomShadow\n",
    ")\n",
    "\n",
    "from albumentations import RandomResizedCrop, CoarseDropout, RandomGridShuffle\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "img_size = 456\n",
    "def get_train_transforms():\n",
    "    return Compose([\n",
    "            # CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            #Resize(CFG['img_size'], CFG['img_size']),\n",
    "            SmallestMaxSize(img_size,interpolation=2, p=1.),\n",
    "\n",
    "            CenterCrop(img_size, img_size, p=1.),\n",
    "\n",
    "            #RandomResizedCrop(img_size, img_size),\n",
    "            Transpose(p=0.5),\n",
    "            Flip(p=0.5),\n",
    "            # VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            # RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            # Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            # CoarseDropout(p=0.5),\n",
    "            # Cutout(p=0.5),\n",
    "            RandomGridShuffle(grid=(3, 3), p=0.5),  \n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "  \n",
    "        \n",
    "def get_valid_transforms():\n",
    "    return Compose([\n",
    "            SmallestMaxSize(img_size,interpolation=2, p=1.),\n",
    "\n",
    "            CenterCrop(img_size, img_size, p=1.),\n",
    "            # CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            # Resize(CFG['img_size'], CFG['img_size']),\n",
    "            # Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)\n",
    "\n",
    "def get_inference_transforms():\n",
    "    return Compose([\n",
    "            RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg9k82M6m_KY"
   },
   "outputs": [],
   "source": [
    "def show_transforms():\n",
    "    return Compose([\n",
    "            #CenterCrop(CFG['img_size'], CFG['img_size'], p=1.),\n",
    "            SmallestMaxSize(img_size,interpolation=2, p=1.),\n",
    "\n",
    "            CenterCrop(img_size, img_size, p=1.),\n",
    "                    \n",
    "            #RandomResizedCrop(CFG['img_size'], CFG['img_size']),\n",
    "            # Transpose(p=0.5),\n",
    "            # HorizontalFlip(p=0.5),\n",
    "            # VerticalFlip(p=0.5),\n",
    "            # ShiftScaleRotate(p=0.5),\n",
    "            # HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            # RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            # #Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
    "            # CoarseDropout(p=0.5),\n",
    "            # Cutout(num_holes=20, max_h_size=20, max_w_size=20, fill_value=(128,128,128), p=0.5),   \n",
    "            # RandomGridShuffle(grid=(4, 4), p=0.5),    \n",
    "            #RandomSunFlare(flare_roi=(0, 0, 1, 1), num_flare_circles_lower=10, num_flare_circles_upper=20, angle_lower=0.5, src_radius=100,  p=1),\n",
    "            #RandomShadow(num_shadows_lower=1, num_shadows_upper=1, shadow_dimension=3, shadow_roi=(0, 0.5, 1, 1), p=1),\n",
    "            #Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "\n",
    "        ], p=1.)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3NPycdiZl4UQ",
    "outputId": "5e5c1832-feb3-4940-aa7c-fa33e32f7c42"
   },
   "outputs": [],
   "source": [
    "transforms = show_transforms()\n",
    "images = read_random_images(train_imades, 16)\n",
    "\n",
    "images = [\n",
    "    (title, transforms(image=i)[\"image\"])\n",
    "    for (title, i) in images\n",
    "]\n",
    "show_examples(images);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wr1j9WEyohfY"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x1ZjaSGBohfY"
   },
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, df, data_root, transforms=None, output_label=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True).copy()\n",
    "        self.transforms = transforms\n",
    "        self.data_root = data_root\n",
    "        self.output_label = output_label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        # get labels\n",
    "        if self.output_label:\n",
    "            target = self.df.iloc[index]['label']\n",
    "          \n",
    "        #path = \"{}/{}\".format(self.data_root, self.df.iloc[index]['image_id'])\n",
    "        # root / 'test_images/'\n",
    "\n",
    "        path = self.data_root / self.df.iloc[index]['image_id']\n",
    "        img  = get_img(path)\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)['image']\n",
    "            \n",
    "        # do label smoothing\n",
    "        if self.output_label == True:\n",
    "            return img, target\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ut1f4FTr38qP"
   },
   "outputs": [],
   "source": [
    "# def get_loaders(fold: int, BS: int, img_size: int=224, waveform_transforms=None):\n",
    "\n",
    "#     train_all = pd.read_csv(INPUT_ROOT / \"train_all.csv\")[:100]\n",
    "\n",
    "#     # # split dataset\n",
    "#     train_file_list = train_all.query(\"fold != @fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
    "#     val_file_list = train_all.query(\"fold == @fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
    "\n",
    "#     print(\"[fold {}] train: {}, val: {}\".format(fold, len(train_file_list), len(val_file_list)))\n",
    "\n",
    "#     # # make dataset\n",
    "#     train_dataset = SpectrogramDataset(train_file_list,\n",
    "#                                         img_size=img_size,\n",
    "#                                         waveform_transforms=waveform_transforms,\n",
    "#                                         spectrogram_transforms=None,) #**args_dataset)\n",
    "#     val_dataset = SpectrogramDataset(val_file_list,\n",
    "#                                         img_size=img_size,\n",
    "#                                         waveform_transforms=None,\n",
    "#                                         spectrogram_transforms=None,) #**args_dataset)\n",
    "#     # # make dataloader\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=4, pin_memory=True, drop_last=True )#**args_loader[\"train\"])\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=True, num_workers=4, pin_memory=True, drop_last=True) #**args_loader[\"val\"])\n",
    "    \n",
    "#     return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uE1yjiqq-9YE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "t9am3Yal-v2p",
    "outputId": "f5d1882e-5523-449a-d073-607866ea6b61"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=7, random_state=SEED, shuffle=True)\n",
    "\n",
    "for  i, (train_index, test_index) in enumerate(skf.split(train['image_id'], train['label'])):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    train[f\"fold_{i}\"] = \"train\"\n",
    "    train[f\"fold_{i}\"][test_index] = \"test\"\n",
    "    sns.histplot(train[f\"fold_{i}\"])\n",
    "    # X_train, X_test = X[train_index], X[test_index]\n",
    "    # y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3I-L-WlO2UY0"
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "train_ds = CassavaDataset(train[train[f\"fold_{i}\"] == 'train'], root / 'train/', transforms=get_train_transforms())\n",
    "        \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "            train_ds, \n",
    "            batch_size=1,\n",
    "            num_workers=CFG['num_workers'],\n",
    "            shuffle=True,\n",
    "            pin_memory=False,\n",
    "        )\n",
    "\n",
    "test_ds = CassavaDataset(train[train[f\"fold_{i}\"] == 'test'], root / 'train/', transforms=get_valid_transforms())\n",
    "        \n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "            test_ds, \n",
    "            batch_size=1,\n",
    "            #num_workers=CFG['num_workers'],\n",
    "            shuffle=False,\n",
    "            pin_memory=False,\n",
    "        )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZU1oalvzyrOd"
   },
   "outputs": [],
   "source": [
    "loaders = collections.OrderedDict()\n",
    "loaders[\"train\"] = train_loader\n",
    "loaders[\"valid\"] = valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPRjcRBIzdsp",
    "outputId": "553e2c50-1442-4d82-ed95-266a38d02d2b"
   },
   "outputs": [],
   "source": [
    "next(iter(loaders[\"train\"]))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "XWci_L1lJWFl",
    "outputId": "84381572-ee97-489a-c666-a70ab5d2ee35"
   },
   "outputs": [],
   "source": [
    "plt.imshow(train_ds[0][0].transpose(0, 2));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PX6k-CGWohfc"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mt3n0csWohfc"
   },
   "outputs": [],
   "source": [
    "class CassvaImgClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_arch, pretrained=pretrained)\n",
    "        n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Linear(n_features, n_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    \n",
    "class EnsembleClassifier(nn.Module):\n",
    "    def __init__(self, model_arch, n_class, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model1 = VisionTransformer.from_pretrained('ViT-B_32', num_classes=5) \n",
    "        #self.model1.load_state_dict(torch.load('../input/vit-model-1/ViT-B_16.pt'))\n",
    "        self.model2 = CassvaImgClassifier(model_arch, n_class, pretrained)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.model1(x)\n",
    "        x2 = self.model2(x)\n",
    "        return 0.6 * x1 + 0.4 * x2\n",
    "    \n",
    "    def load(self, state_dict):\n",
    "        self.model2.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "td0kpl92vkJp"
   },
   "outputs": [],
   "source": [
    "def get_model(model_name: str, num_classes: int, pretrained: str = \"imagenet\"):\n",
    "\n",
    "    if 'resne' in model_name:\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        dim_feats = model.fc.in_features\n",
    "        model.fc = nn.Linear(dim_feats, num_classes)\n",
    "    else:\n",
    "        model = timm.create_model(model_name, pretrained=True)\n",
    "        dim_feats = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(dim_feats, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_lr(model_name: str, head_lr=3e-4, reduce=0.1):\n",
    "\n",
    "    if 'resnet' in model_name:\n",
    "        # Set params for se_resnet\n",
    "        lr = [\n",
    "            #{'params': model.conv1.parameters(), 'lr': head_lr * reduce * reduce}, \n",
    "            {'params': model.layer1.parameters(), 'lr': head_lr * reduce * reduce}, \n",
    "            {'params': model.layer2.parameters(), 'lr': head_lr * reduce}, \n",
    "            {'params': model.layer3.parameters(), 'lr': head_lr * reduce * 1.5}, \n",
    "            {'params': model.layer4.parameters(), 'lr': head_lr * reduce * 1.5}, \n",
    "            {'params': model.last_linear.parameters(), 'lr': head_lr},\n",
    "        ]\n",
    "    elif 'seresnext' in model_name:    \n",
    "        # Set params for resnext\n",
    "        lr = [\n",
    "            #{'params': model.layer0.parameters(), 'lr': head_lr * reduce * reduce}, \n",
    "            {'params': model.layer1.parameters(), 'lr': head_lr * reduce}, \n",
    "            {'params': model.layer2.parameters(), 'lr': head_lr * reduce}, \n",
    "            {'params': model.layer3.parameters(), 'lr': head_lr * reduce * 1.5}, \n",
    "            {'params': model.layer4.parameters(), 'lr': head_lr * reduce * 1.5}, \n",
    "            {'params': model.fc.parameters(), 'lr': head_lr},\n",
    "        ]\n",
    "    else:\n",
    "        # Set params for efficientnet\n",
    "        lr = [\n",
    "            {'params': model.conv_stem.parameters(), 'lr': reduce * reduce},\n",
    "            {'params': model.blocks.parameters(), 'lr': reduce},\n",
    "            {'params': model.conv_head.parameters(), 'lr': reduce * 1.5},\n",
    "            {'params': model.classifier.parameters(), 'lr': head_lr},\n",
    "        ]\n",
    "\n",
    "    return lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X_f8_MxoqJDB",
    "outputId": "0e0131a0-eda4-455e-8efb-a792b1b2393d"
   },
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "print(f\"device: {device}\")\n",
    "#model = EnsembleClassifier(CFG['model_arch'], train.label.nunique()).to(device)\n",
    "\n",
    "num_classes = 5\n",
    "model_name = 'tf_efficientnet_b0_ns'  #\"seresnext50_32x4d\"\n",
    "model = get_model(model_name, num_classes)\n",
    "lr = get_lr(model_name, 3e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxHTLnBWohfd"
   },
   "source": [
    "# Main Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzdzufE9plAQ",
    "outputId": "1cf13fdc-ecb0-4a65-83f8-1a0ab689f469"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-bc273f8721ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# minimize_metric=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     verbose=True)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/runners/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     def infer(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     ):\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# @TODO: how to remove self duplication? and does it really matter?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_substring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_exception_handler_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_experiment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_experiment_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_experiment_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_stage_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# @TODO: how to remove self duplication? and does it really matter?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_substring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mon_stage_start\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    867\u001b[0m             \u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             \u001b[0mdistributed_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m         )\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/utils/components.py\u001b[0m in \u001b[0;36mprocess_components\u001b[0;34m(model, criterion, optimizer, scheduler, distributed_params, device)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;34m\"You must choose only one mixed precision backend\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_recursive_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_ddp_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/catalyst/utils/misc.py\u001b[0m in \u001b[0;36mmaybe_recursive_call\u001b[0;34m(object_or_dict, method, recursive_args, recursive_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0mr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecursive_kwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_or_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_or_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mr_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mr_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.AdamW(lr)\n",
    "#base_optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001) # model_params, weight_decay=0.0003)\n",
    "optimizer = torch.optim.AdamW(lr)\n",
    "#optimizer = Lookahead(base_optimizer)\n",
    "scheduler = OneCycleLRWithWarmup(\n",
    "    optimizer, \n",
    "    num_steps=10, \n",
    "    lr_range=(0.005, 0.0001),\n",
    "    warmup_steps=1)\n",
    "logdir = f\"{root}/logs_{22}\"\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.7, patience=2)\n",
    "runner = SupervisedRunner(device=device)\n",
    "\n",
    "runner.train(\n",
    "                    model=model,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    scheduler=scheduler,\n",
    "                    loaders=loaders,\n",
    "                    callbacks=[\n",
    "                            AccuracyCallback(),\n",
    "                        # F1ScoreCallback(\n",
    "                        #     input_key=\"targets_one_hot\",\n",
    "                        #     activation=\"Softmax\")\n",
    "                        OptimizerCallback(accumulation_steps=16),\n",
    "                        ],\n",
    "                    logdir=logdir,\n",
    "                    num_epochs=30,\n",
    "                    # main_metric= \"accuracy\",\n",
    "                    # minimize_metric=False,\n",
    "    \n",
    "                    fp16=True,\n",
    "                    verbose=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCpEvFGa-BB7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vit-cuda-as-usual-ensemble-inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda58946a75f4004287abb6743deef6d20e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
